---
title: "Practicum II - Mine a Database, CS5200 Spring 2021"
output: html_notebook
---


### Part 1 Load XML: Create a normalized relational OLTP database
```{r}
#pacman (package manager) installs and loads packages if not installed
pacman::p_load(pacman, RSQLite, XML, DBI, tidyverse, dplyr)
install.packages("dplyr") 

#create db to set schema and load data to
dbs <- dbConnect(RSQLite::SQLite(), "pubMed0.db")

```

### Part 1 Populate relational database with data from an XML document



```{r}

path <- "/Users/jeannille/repos/mine_a_database/"
xmlFile <- "pubmed_sample.xml"
fpn <- paste0(path,xmlFile)

xml_data <- xmlParse(file = fpn)
nodes <- getNodeSet(xml_data, "//PubmedArticle") 
r <- xmlRoot(xml_data)

# Get the name of the node to confirm
xmlName(r)
#PubmedArticleSet

#get number of children of root, number of pubMedArticles (19)
numPubMeds <- xmlSize(r)


```


```{r}

newJournal.df <- data.frame(ISSN = character(),#cant be numeric with a hyphen?
                          journalTitle = character(),
                          ISOabbrevation = character(),
                          volume = numeric(),
                          Issue = numeric(),
                          #pubYear = numeric(),
                          #pubMonth = character(),
                          stringsAsFactors = F)

colnames(newJournal.df) <- c("ISSN","journalTitle", 
                             "ISOabbrevation","Issue","volume")#,"pubYear","pubMonth")

r <- xmlRoot(xml_data)

for (m in 1:19)
{

  aJournalNode <- r[[m]][[1]][['Article']][['Journal']] #

  aJournal <- aJournalNode[[m]]
  ISSN <- xpathSApply(aJournalNode, "./ISSN", xmlValue)
  journalTitle <- xpathSApply(aJournalNode, "./Title", xmlValue)
  ISOabbrevation <- xpathSApply(aJournalNode, "./ISOAbbreviation", xmlValue)
  volume<-xpathSApply(aJournalNode, "./JournalIssue/Volume", xmlValue)
  Issue <-xpathSApply(aJournalNode, "./JournalIssue/Issue", xmlValue)
  
  #pubYear<-xpathSApply(aJournalNode, "./JournalIssue/PubDate/Year", xmlValue)
  #pubMonth <-xpathSApply(aJournalNode, "./JournalIssue/PubDate/Month", xmlValue)
    
    
  if (length(ISSN) == 0)
    ISSN <- ""
  if (length(journalTitle) == 0)
    journalTitle <- ""
  if (length(ISOabbrevation) == 0)
    ISOabbrevation <- ""
  #if (length(pubMonth) == 0)
  #  pubMonth <- ""

  newJournal.df[m,1] <- ISSN
  newJournal.df[m,2] <- journalTitle
  newJournal.df[m,3] <- ISOabbrevation
  newJournal.df[m,4] <- volume
  newJournal.df[m,5] <- Issue
  #newJournal.df[m,6] <- pubYear
  #newJournal.df[m,7] <- pubMonth
}
  
```

```{r}
#commented out so not seen in a knitted file
newJournal.df
```


```{r}
newArticle.df <- data.frame(PMID = numeric(), #
                          journalISSN = character(),
                          articleTitle = character(),
                          pagination = character(),
                          #elocationID can have more then 1. need another table for that?
                          #same with abstract
                          #and author list- different table? what to use as a key?
                          language = character(),
                          #grant list?
                          #publication type tist?
                          artYear = numeric(),
                          artMonth = numeric(),
                          artDay = numeric(),
                          pubYear = numeric(),
                          pubMonth = character(),
                          stringsAsFactors = F)

colnames(newArticle.df) <- c("PMID","journalISSN", 
                             "articleTitle","pagination","language", 
                             "artYear", "artMonth", "artDay", 'pubYear', "pubMonth")#

r <- xmlRoot(xml_data)

for (m in 1:19)
{
  
  anArticleNode <- r[[m]][[1]][['Article']]#[['Journal']] #

  PMID <- xpathSApply(r[[m]][[1]], "./PMID", xmlValue)
  journalISSN <- xpathSApply(anArticleNode, "./Journal/ISSN", xmlValue)
  articleTitle <- xpathSApply(anArticleNode, "./ArticleTitle", xmlValue)
  pagination <- xpathSApply(anArticleNode, "./Pagination/MedlinePgn", xmlValue)
  language <- xpathSApply(anArticleNode, "./Language", xmlValue)
  
  artYear <- xpathSApply(anArticleNode, "./ArticleDate/Year", xmlValue)
  artMonth <- xpathSApply(anArticleNode, "./ArticleDate/Month", xmlValue)
  artDay <- xpathSApply(anArticleNode, "./ArticleDate/Day", xmlValue)
  
  pubYear <- xpathSApply(anArticleNode, "./Journal/JournalIssue/PubDate/Year", xmlValue)
  pubMonth <- xpathSApply(anArticleNode, "./Journal/JournalIssue/PubDate/Month", xmlValue)
  
  
  if (length(PMID) == 0)
    PMID <- ""
  if (length(journalISSN) == 0)
    journalISSN <- ""
  if (length(articleTitle) == 0)
    articleTitle <- ""
  if (length(pagination) == 0)
    pagination <- ""
  if (length(language) == 0)
    language <- ""
  if (length(artYear) == 0)
    artYear <- ""
  if (length(artMonth) == 0)
    artMonth <- ""
  if (length(artDay) == 0)
    artDay <- ""
  
  if (length(pubYear) == 0)
    pubYear <- ""
  if (length(pubMonth) == 0)
    pubMonth <- ""

  newArticle.df[m,1] <- PMID
  newArticle.df[m,2] <- journalISSN
  newArticle.df[m,3] <- articleTitle
  newArticle.df[m,4] <- pagination
  newArticle.df[m,5] <- language
  newArticle.df[m,6] <- artYear
  newArticle.df[m,7] <- artMonth
  newArticle.df[m,8] <- artDay
  newArticle.df[m,9] <- pubYear
  newArticle.df[m,10] <- pubMonth
}

```

```{r}
#commented out so not seen in a knitted file
newArticle.df
```

```{r}

newAuthor.df <- data.frame(PMID = numeric(),
                          lastName = character(),
                          foreName = character(),
                          initials = character(),
                          affiliation = character(),
                          stringsAsFactors = F)

colnames(newAuthor.df) <- c("PMID","lastName","foreName", 
                             "initials","affiliation")

r <- xmlRoot(xml_data)
rowCount <- 1
for (m in 1:19)
{

  PMID <- xpathSApply(r[[m]][[1]], "./PMID", xmlValue)
  if (length(PMID) == 0)
    PMID <- ""
  
  anAuthorNodeList <- r[[m]][[1]][['Article']][['AuthorList']] 
  
  j<-xmlSize(anAuthorNodeList)
  
  
  for (k in 1:j){
    
    node <-anAuthorNodeList[[k]]
    lastName <- xpathSApply(node, "./LastName", xmlValue)
    foreName <- xpathSApply(node, "./ForeName", xmlValue)
    initials <- xpathSApply(node, "./Initials", xmlValue)
    affiliation <- xpathSApply(node, "./Affiliation", xmlValue)
    
    if (length(lastName) == 0)
      lastName <- ""
    if (length(foreName) == 0)
      foreName <- ""
    if (length(initials) == 0)
      initials <- ""
    if (length(affiliation) == 0)
      affiliation <- ""
    
    newAuthor.df[rowCount,1] <- PMID
    newAuthor.df[rowCount,2] <- lastName
    newAuthor.df[rowCount,3] <- foreName
    newAuthor.df[rowCount,4] <- initials
    newAuthor.df[rowCount,5] <- affiliation
    
    
    rowCount <- rowCount+1
  }

}
  
```
```{r}
#commented out so not seen in a knitted file
#newAuthor.df
```


```{r}

newHistory.df <- data.frame(PMID = numeric(),
                          pubStatus = character(),
                          year = numeric(),
                          month = numeric(),
                          day = numeric(),
                          #hour and minute not useful for analysis?
                          stringsAsFactors = F)

colnames(newHistory.df) <- c("PMID","pubStatus","year", 
                             "month","day")

r <- xmlRoot(xml_data)
rowCount <- 1
for (m in 1:19)
{

  PMID <- xpathSApply(r[[m]][[1]], "./PMID", xmlValue)
  if (length(PMID) == 0)
    PMID <- ""
  
  aHistoryList <- r[[m]][['PubmedData']][['History']]
  
  j<-xmlSize(aHistoryList)
  
  
  for (k in 1:j){
    
    node <-aHistoryList[[k]]
    
    pubStatus <- xmlGetAttr(node,'PubStatus')

    year <- xpathSApply(node, "./Year", xmlValue)
    month <- xpathSApply(node, "./Month", xmlValue)
    day <- xpathSApply(node, "./Day", xmlValue)
    

    if (length(pubStatus) == 0)
      pubStatus <- ""
    if (length(year) == 0)
      year <- ""
    if (length(month) == 0)
      month <- ""
    if (length(day) == 0)
      day <- ""
    
    newHistory.df[rowCount,1] <- PMID
    newHistory.df[rowCount,2] <- pubStatus
    newHistory.df[rowCount,3] <- year
    newHistory.df[rowCount,4] <- month
    newHistory.df[rowCount,5] <- day
    
    
    rowCount <- rowCount+1
  }

}
  
```


```{r}
#commented out so not seen in a knitted file
newHistory.df
```



Clear tables as needed

```{sql connection=dbs}
DROP TABLE IF EXISTS Journal
```

```{sql connection=dbs}
DROP TABLE IF EXISTS Article
```

```{sql connection=dbs}
DROP TABLE IF EXISTS Authorship
```

```{sql connection=dbs}
DROP TABLE IF EXISTS Author
```

```{sql connection=dbs}
DROP TABLE IF EXISTS History

```


Create tables from ERD

```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Journal (
  ISSN varchar(255) PRIMARY KEY,
  title varchar(255),
  ISOabbrevation varchar(255), 
  volume varchar(255), 
  issue varchar(255)

  );
```

  
```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Article (
  PMID int(255) NOT NULL,
  journalISSN varchar(255),
  title varchar(255),
  pagination varchar(255),
  language varchar(255),
  FOREIGN KEY (journalISSN ) REFERENCES Journal(ISSN)
  );
```

  histKey INTEGER primary key AUTOINCREMENT,
  
  use compound key instead?
  

```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS History (
  PMID int(255),
  pubStatus varchar(255),
  year int(255),
  month int(255),
  day int(255),
  PRIMARY  KEY (PMID, pubStatus),
  FOREIGN KEY (PMID) REFERENCES Article(PMID)
  );
```

adding in this lookup table
might need compound primary key?
```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Authorship (
  lookupKey INTEGER primary key AUTOINCREMENT,
  PMID int(255),
  lastName varchar(255),
  foreName varchar(255),
  FOREIGN KEY (PMID) REFERENCES Article(PMID),
  FOREIGN KEY (lastName, foreName) REFERENCES Author(lastName, foreName)
  );
```

  PMID int(255),
  
  ,
  FOREIGN KEY (PMID) REFERENCES Article(PMID)
```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Author (
  authorKey INTEGER primary key AUTOINCREMENT,
  lastName varchar(255),
  foreName varchar(255),
  initials varchar(255),
  affiliation varchar(255)
  );
```



Check all tables have been correctly added to database
```{r}
dbListTables(dbs)

```



16 distinct journals, but dbs will remain with the 3 dups for purposes of querying 
```{sql connection=dbs, output.var="df_journalData"}
SELECT ISSN,journalTitle,ISOabbrevation, volume, issue from journalData 
GROUP BY ISSN

```
Part 1 Journal table

Inserting data (dataframe) into tables that have been created in pubMedData database

```{r}
dbWriteTable(dbs, "Journal",df_journalData , overwrite = TRUE)
dbReadTable(dbs, 'Journal')

```


Drop temporary table for Journal
```{sql connection=dbs}
DROP TABLE journalData
```

write article df to database
```{r}
dbWriteTable(dbs, "articleData",newArticle.df )
```


```{sql connection=dbs}

SELECT distinct PMID from articleData
```

Remove year/ month/day?
, year,month,day
, artYear,artMonth,artDay
```{sql connection=dbs}
INSERT INTO Article (PMID , journalISSN, title, pagination,language)
SELECT  PMID, journalISSN, articleTitle, pagination,language
FROM articleData


```

```{sql connection=dbs}

SELECT * from Article LIMIT 10
```

```{sql connection=dbs}
DROP TABLE articleData
```


```{r}
dbWriteTable(dbs, "histData",newHistory.df , overwrite = TRUE)
```

History information for the 19 published articles, use year-month-date form this table for star schema
```{sql connection=dbs}

SELECT  DiSTINCT * FROM histData  WHERE pubStatus = "pubmed" 
```

```{sql connection=dbs}
INSERT INTO History (PMID , pubStatus, year, month,day)
SELECT  PMID , pubStatus, year, month,day
FROM histData


```


```{sql connection=dbs}

SELECT * from History LIMIT 10
```


```{r}
dbWriteTable(dbs, "authorData",newAuthor.df, overwrite = TRUE)
```



```{sql connection=dbs}

SELECT * from authorData LIMIT 10
```

Use SQL INSERT INTO to populate Author table of OLAP database
```{sql connection=dbs}
INSERT INTO Author ( lastName, foreName, initials,affiliation)
SELECT   lastName, foreName, initials,affiliation
FROM authorData

```

```{sql connection=dbs}

SELECT distinct * from Author limit 10
```


Initials is not included in the keys for Authorship because it dosent impact the results. 84 unique first and last name pairs, and 84 first, last and initial pairs.
```{sql connection=dbs}
INSERT INTO Authorship ( PMID, lastName, foreName)
SELECT   PMID, lastName, foreName
FROM authorData
```

Total Authorship (can include author multiple times as they can contirbute to multiple instances of articles, 272 rows)
```{sql connection=dbs}

SELECT DISTINCT * from Authorship LIMIT 10
```

Drop tempororay authorData table
```{sql connection=dbs}
DROP TABLE authorData
```

### Part 2 Star schema, establish connection to star schema db
```{r}
star.dbs <- dbConnect(RSQLite::SQLite(), "pubMedStar0.db")
```

```{sql connection=star.dbs}
--use to clear tables at start
DROP TABLE IF EXISTS dimAuthor;
```

```{sql connection=star.dbs}
DROP TABLE IF EXISTS dimPubDate;
```

```{sql connection=star.dbs}
DROP TABLE IF EXISTS dimJournal;
```

```{sql connection=star.dbs}
DROP TABLE IF EXISTS dimHistory;
```

```{sql connection=star.dbs}
DROP TABLE IF EXISTS factArticle;

```

tracks number of articles per quarter, month, year
```{sql connection=star.dbs}
DROP TABLE IF EXISTS numArticleSummary;
```

## realize star schema tables
```{sql connection=star.dbs}
CREATE TABLE IF NOT EXISTS dimAuthor(
  authorRef INTEGER, 
 -- PMID INTEGER NOT NULL,
  lastName TEXT,
  foreName TEXT,
  initials TEXT,
  affiliation TEXT, 
  PRIMARY KEY(authorRef) 
  );
```

#pubMedDate col
```{sql connection=star.dbs}
CREATE TABLE IF NOT EXISTS dimPubDate(
  dateRef INTEGER PRIMARY KEY AUTOINCREMENT,
  PMID INTEGER,
  datePublished TEXT,
  month INTEGER,
  day INTEGER,
  year INTEGER,
  quarter INTEGER
  );

```

update this to associate with every article (even if multiple articles published to same journal, dimension table should focus on articles in a particular context, center table?, or could just grab from article itself)
```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS dimJournal(
  journalRef INTEGER PRIMARY KEY AUTOINCREMENT,
  ISSN TEXT,
  title TEXT,
  ISOabbrevation TEXT
  --volume TEXT NULL,
  --issue TEXT NULL,
  );

```


```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS dimHistory(
  historyRef INTEGER PRIMARY KEY AUTOINCREMENT,
  articleId INTEGER,
  articleTitle TEXT,
  pubStatus INTEGER
  );

```


factArticle compound key - (pmid, authorRef) connect author to specific article
```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS factArticle(
  PMID INTEGER,
  articleTitle TEXT,
  authorRef INTEGER,  
  journalRef INTEGER, 
  dateRef INTEGER, 
  historyRef INTEGER,
  FOREIGN KEY (authorRef) REFERENCES dimAuthor(authorRef),
  FOREIGN KEY (journalRef) REFERENCES dimJournal(journalRef), 
  FOREIGN KEY (dateRef) REFERENCES dimPubDate(dateRef),
  FOREIGN KEY (historyRef) REFERENCES dimHistory(historyRef),
  PRIMARY KEY (PMID)
);

```


```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS numArticleSummary(
  summaryId INTEGER PRIMARY KEY AUTOINCREMENT,
  numOfArticles INTEGER NOT NULL,
  quarter INTEGER,
  year INTEGER, 
  month INTEGER
);

```




```{r}
dbListTables(star.dbs)
dbListTables(dbs)
```


Purpose of star schema is to have eaisly accessible look up tables (LinkedIn learning) - Context tables 
Part 2. Populate Star Schema tables using populated OLTP database. 
First, update the dimension tables. Then we can use look up keys for these to  populate 

Create temp (star schema) data frames from dbs database using queries to populate Star Schema tables

```{r}

#dbs <- dbConnect(RSQLite::SQLite(), "pubMed0.db")
#query database to get author
#dbSendQuery(dbs, "SELECT * FROM Author LIMIT 10")

sqlCmd = "SELECT authorKey FROM Author"
authorRef = dbGetQuery(dbs, sqlCmd)
#authorRef 

sqlCmd = "SELECT foreName FROM Author"
foreName = dbGetQuery(dbs, sqlCmd)
#foreName

sqlCmd = "SELECT lastName FROM Author"
lastName = dbGetQuery(dbs, sqlCmd)
#lastName
 
sqlCmd = "SELECT initials FROM Author"
initials = dbGetQuery(dbs, sqlCmd)
#initials

sqlCmd = "SELECT affiliation  FROM Author"
affiliation  = dbGetQuery(dbs, sqlCmd)
#affiliation 

df_AuthorStar = data.frame(cbind(authorRef, foreName, lastName, initials, affiliation))
#df_AuthorStar

head(df_AuthorStar)

#headers of dataframe once collected cols from dbs
#names(df_AuthorStar)
#rename authorKey for star schema table
df_AuthorStar <- df_AuthorStar %>% rename(authorRef = authorKey)
#names(df_AuthorStar)
df_AuthorStar

```

Populate Star schema tables 
```{r}
#star.dbs <- dbConnect(RSQLite::SQLite(), "pubMedStar0.db")

dbWriteTable( star.dbs, "dimAuthor", df_AuthorStar, field.types = NULL, row.names = FALSE, 
              overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimAuthor")

#dbListTables(star.dbs)
```



```{r}
#issn <- dbGetQuery(dbs, "SELECT ISSN FROM JOURNAL")

#journalTitle <- dbGetQuery(dbs, "SELECT TITLE FROM JOURNAL")

#df_Journal = cbind(issn,journalTitle)

jounalDim <- dbGetQuery(dbs, "SELECT ISSN, Journal.title, Journal.ISOabbrevation FROM Journal 
                          INNER JOIN Article ON Journal.ISSN = Article.journalISSN")
jounalDim

dbWriteTable( star.dbs, "dimJournal", jounalDim, field.types = NULL, row.names = FALSE, 
              overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimJournal")
```


```{sql connection=star.dbs}
SELECT * FROM dimJournal LIMIT 10;
```

Populate article fact table now that dimension/context tables have been populated 

```{r}

sqlCmd = "SELECT * FROM Article "
title = dbGetQuery(dbs, sqlCmd)
title

sqlCmd = "SELECT * FROM dimHistory "
historyRef = dbGetQuery(star.dbs, sqlCmd)
#historyRef

sqlCmd = "SELECT* FROM dimAuthor GROUP BY "
authorRef = dbGetQuery(star.dbs, sqlCmd)
authorRef

sqlCmd = "SELECT historyRef FROM dimHistory "
historyRef = dbGetQuery(star.dbs, sqlCmd)
historyRef

sqlCmd = "SELECT journalRef FROM dimJournal"
journalRef = dbGetQuery(star.dbs, sqlCmd)
journalRef

sqlCmd = "SELECT * FROM dimPubDate"
dateRef = dbGetQuery(star.dbs, sqlCmd)
dateRef

df_factArt = cbind(authorRef,journalRef,dateRef,historyRef)
head(df_factArt)

dbWriteTable( star.dbs, "dimJournal", df_Journal, field.types = NULL, row.names = FALSE, 
              overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimJournal")

dbListTables(star.dbs)

#can query here to get artciles per quarter and other facts etc


```


queries db and result outputs into dataframe with pubstates, date and quarter
output will be used to write to dimPubDate and dimHistory in star schema db
```{sql connection=dbs, output.var="df_dimHistory"}

SELECT History.PMID AS PMID,
  History.pubStatus AS pubStatus,
  History.day || "-" || History.month || "-" || History.year AS datePublished,
  CASE
    WHEN History.month BETWEEN 1 AND 3 THEN 1
    WHEN History.month BETWEEN 4 AND 6 THEN 2
    WHEN History.month BETWEEN 7 AND 9 THEN 3
    WHEN History.month Between 10 AND 12 THEN 4
  END AS quarter
  FROM History

```



Query database to populate dimPubDate table (date dimension table)
## Output dimensoon table: dimHistory articleId, articleTitle, pubStatus
```{r}

sqlCmd = "SELECT day FROM History"
Day0 = dbGetQuery(dbs, sqlCmd)
#Day0

sqlCmd = "SELECT month FROM History"
Month0 = dbGetQuery(dbs, sqlCmd)
#Month0

sqlCmd = "SELECT year FROM History"
Year0 = dbGetQuery(dbs, sqlCmd)

sqlCmd = "SELECT pubStatus FROM History"
pubtatus = dbGetQuery(dbs, sqlCmd)

#create date string from day month yr columns queried
dfTest<-cbind(Day0,Month0,Year0, stringsAsFactors = FALSE)
#append full date column to dfTest, redult df of article stages by dates, mo, yr, day 
dfTest$date <- paste(dfTest$day,dfTest$month,dfTest$year, sep = '-')
#dfTest

PMID <- df_dimHistory$PMID
quarter <- df_dimHistory$quarter

#probably not the best way to bind but every pub stage of an article (pubstatus) to align with title
#in order to add to history, i think it can be queries for useful history timeline of each article
sqlCmd = "SELECT History.pubStatus, Article.title
FROM History
JOIN Article ON History.PMID = Article.PMID;"
pubAndTitle = dbGetQuery(dbs, sqlCmd)
pubAndTitle

sqlCmd = "SELECT title FROM Article"
articleTitle = dbGetQuery(dbs, sqlCmd)

#create dataframe for dimHistory dimension table
df_dHistory <- data.frame(cbind(PMID,pubAndTitle))
df_dHistory<- df_dHistory %>% rename(articleId = PMID)
df_dHistory<- df_dHistory %>% rename(articleTitle = title)
df_dHistory

# insert History df to history dimension table of star schema
dbWriteTable( star.dbs, "dimHistory", df_dHistory, field.types = NULL, row.names = FALSE,
               overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimHistory")


```

## Dimensoon table: dimPubDate
Populate the dimension pubDate table of star schema and read the table to confirm its populated
Fields: historyRef, articleId (pmid), articleTitle, pubStatus
```{r}

#create dataframe for pubDate dimension table
df_pubDateStar <- data.frame(cbind(PMID,date1,quarter)) 
df_pubDateStar <- df_pubDateStar %>% rename(datePublished = date)
#names(df_pubDateStar) #confirming headers
df_pubDateStar

# insert pubdate df to pubDate dimension table of star schema
dbWriteTable( star.dbs, "dimPubDate", df_pubDateStar2, field.types = NULL, row.names = FALSE,
               overwrite = FALSE, append = TRUE, allow.keywords = FALSE )


dbReadTable( star.dbs, "dimPubDate")

```



```{sql connection=star.dbs}


```



Join dim tables to create and populate center fact table of star schema
```{sql connection=star.dbs}
INSERT INTO factArticle(authorRef, journalRef, dateRef, historyRef, PMID)
SELECT dimPubDate.dateRef, dimAuthor.authorRef, dimJournal.journalRef, dimHistory.historyRef 
FROM dimPubDate
JOIN dimAuthor ON factArticle.authorRef = dimAuthor.authorRef
JOIN dimJournal ON factArticle.journalRef = dimJournal.journalRef
JOIN dimHistory ON factArticle.historyRef = dimHistory.historyRef
JOIN dimPubDate ON factArticle.dateRef = dimPubDate.dateRef


```


Populate Article Fact table for all 19 articles (will contain all facts queried from all its connected dimension tables) 
```{r}

factPubDate <- dbGetQuery(star.dbs, "SELECT dateRef FROM dimPubDate GROUP BY PMID")
factPubDate

factJournal <- dbGetQuery(star.dbs, "SELECT journalRef FROM dimJournal ")
factJournal

factAuthor <- dbGetQuery(dbs, "SELECT lookupKey AS authorRef FROM Authorship GROUP BY PMID")
factAuthor

factHistory <- dbGetQuery(star.dbs, "SELECT articleId as PMID, historyRef, articleTitle FROM dimHistory GROUP BY articleId")
factHistory

df_factArticle <- data.frame(factPubDate, factJournal, factAuthor, factHistory)
df_factArticle

dbWriteTable( star.dbs, "factArticle", df_factArticle, field.types = NULL, row.names = FALSE,
               overwrite = FALSE, append = TRUE, allow.keywords = FALSE )


dbReadTable( star.dbs, "factArticle")

```



In the same schema as the previous step, create and populate a summary fact table that represents number of articles per time period (quarter, year) by author and by journal. Include the image of an updated ERD that contains the fact table. Populate the fact table in R. When building the schema, look a head to Part 3 as the schema is dependent on the eventual OLAP queries.

Query that sorts by quarter - get from star schema
```{r}


#numArticleSummary numOfArticles, auarter, year, month (summaryId auto)

#subquery that groups by articles, resulting in 19 unique articles and their history
to = " SELECT pmid, quarter FROM dimHistory
GROUP BY PMID "

sqlCmd = " SELECT quarter, COUNT(*) AS 'numOfarticles' FROM (SELECT pmid, quarter FROM dimHistory
GROUP BY PMID) GROUP BY quarter
"
#get mpid and quarter of each unique article
# (SELECT PMID, quarter FROM (SELECT * FROM dimHistory GROUP BY PMID)

sqlCmd = "SELECT  FROM dimHistory GROUP BY articleID"
dbGetQuery(star.dbs, sqlCmd)



```





```{r}
dbListTables(dbs)
dbListTables(star.dbs)


```











Disconnect from both databases
```{r}

dbDisconnect(dbs)
dbDisconnect(star.dbs)

```


### Part 3 use the OLAP star/snowflake schema to do some (simple) data mining




Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

