---
title: "Practicum II - Mine a Database, CS5200 Spring 2021"
output: html_notebook
---


### Part 1 Load XML: Create a normalized relational OLTP database
```{r}
#pacman (package manager) installs and loads packages if not installed
pacman::p_load(pacman, RSQLite, XML, DBI, tidyverse, dplyr)
install.packages("dplyr") 

#create db to set schema and load data to
dbs <- dbConnect(RSQLite::SQLite(), "pubMed0.db")

```

### Part 1 Populate relational database with data from an XML document
### Part 2 Add to the normalized schema fact tables and turn the normalized schema into a denormalized schema suitable for OLAP


```{r}

path <- "/Users/jeannille/repos/mine_a_database/"
xmlFile <- "pubmed_sample.xml"
fpn <- paste0(path,xmlFile)

xml_data <- xmlParse(file = fpn)
nodes <- getNodeSet(xml_data, "//PubmedArticle") 
r <- xmlRoot(xml_data)

# Get the name of the node to confirm
xmlName(r)
#PubmedArticleSet

#get number of children of root, number of pubMedArticles (19)
numPubMeds <- xmlSize(r)


```


```{r}

newJournal.df <- data.frame(ISSN = character(),#cant be numeric with a hyphen?
                          journalTitle = character(),
                          ISOabbrevation = character(),
                          volume = numeric(),
                          Issue = numeric(),
                          #pubYear = numeric(),
                          #pubMonth = character(),
                          stringsAsFactors = F)

colnames(newJournal.df) <- c("ISSN","journalTitle", 
                             "ISOabbrevation","Issue","volume")#,"pubYear","pubMonth")

r <- xmlRoot(xml_data)

for (m in 1:19)
{

  aJournalNode <- r[[m]][[1]][['Article']][['Journal']] #

  aJournal <- aJournalNode[[m]]
  ISSN <- xpathSApply(aJournalNode, "./ISSN", xmlValue)
  journalTitle <- xpathSApply(aJournalNode, "./Title", xmlValue)
  ISOabbrevation <- xpathSApply(aJournalNode, "./ISOAbbreviation", xmlValue)
  volume<-xpathSApply(aJournalNode, "./JournalIssue/Volume", xmlValue)
  Issue <-xpathSApply(aJournalNode, "./JournalIssue/Issue", xmlValue)
  
  #pubYear<-xpathSApply(aJournalNode, "./JournalIssue/PubDate/Year", xmlValue)
  #pubMonth <-xpathSApply(aJournalNode, "./JournalIssue/PubDate/Month", xmlValue)
    
    
  if (length(ISSN) == 0)
    ISSN <- ""
  if (length(journalTitle) == 0)
    journalTitle <- ""
  if (length(ISOabbrevation) == 0)
    ISOabbrevation <- ""
  #if (length(pubMonth) == 0)
  #  pubMonth <- ""

  newJournal.df[m,1] <- ISSN
  newJournal.df[m,2] <- journalTitle
  newJournal.df[m,3] <- ISOabbrevation
  newJournal.df[m,4] <- volume
  newJournal.df[m,5] <- Issue
  #newJournal.df[m,6] <- pubYear
  #newJournal.df[m,7] <- pubMonth
}
  
```
```{r}
#commented out so not seen in a knitted file
#newJournal.df
```


```{r}
newArticle.df <- data.frame(PMID = numeric(), #
                          journalISSN = character(),
                          articleTitle = character(),
                          pagination = character(),
                          #elocationID can have more then 1. need another table for that?
                          #same with abstract
                          #and author list- different table? what to use as a key?
                          language = character(),
                          #grant list?
                          #publication type tist?
                          artYear = numeric(),
                          artMonth = numeric(),
                          artDay = numeric(),
                          pubYear = numeric(),
                          pubMonth = character(),
                          stringsAsFactors = F)

colnames(newArticle.df) <- c("PMID","journalISSN", 
                             "articleTitle","pagination","language", 
                             "artYear", "artMonth", "artDay", 'pubYear', "pubMonth")#

r <- xmlRoot(xml_data)

for (m in 1:19)
{
  
  anArticleNode <- r[[m]][[1]][['Article']]#[['Journal']] #

  PMID <- xpathSApply(r[[m]][[1]], "./PMID", xmlValue)
  journalISSN <- xpathSApply(anArticleNode, "./Journal/ISSN", xmlValue)
  articleTitle <- xpathSApply(anArticleNode, "./ArticleTitle", xmlValue)
  pagination <- xpathSApply(anArticleNode, "./Pagination/MedlinePgn", xmlValue)
  language <- xpathSApply(anArticleNode, "./Language", xmlValue)
  
  artYear <- xpathSApply(anArticleNode, "./ArticleDate/Year", xmlValue)
  artMonth <- xpathSApply(anArticleNode, "./ArticleDate/Month", xmlValue)
  artDay <- xpathSApply(anArticleNode, "./ArticleDate/Day", xmlValue)
  
  pubYear <- xpathSApply(anArticleNode, "./Journal/JournalIssue/PubDate/Year", xmlValue)
  pubMonth <- xpathSApply(anArticleNode, "./Journal/JournalIssue/PubDate/Month", xmlValue)
  
  
  if (length(PMID) == 0)
    PMID <- ""
  if (length(journalISSN) == 0)
    journalISSN <- ""
  if (length(articleTitle) == 0)
    articleTitle <- ""
  if (length(pagination) == 0)
    pagination <- ""
  if (length(language) == 0)
    language <- ""
  if (length(artYear) == 0)
    artYear <- ""
  if (length(artMonth) == 0)
    artMonth <- ""
  if (length(artDay) == 0)
    artDay <- ""
  
  if (length(pubYear) == 0)
    pubYear <- ""
  if (length(pubMonth) == 0)
    pubMonth <- ""

  newArticle.df[m,1] <- PMID
  newArticle.df[m,2] <- journalISSN
  newArticle.df[m,3] <- articleTitle
  newArticle.df[m,4] <- pagination
  newArticle.df[m,5] <- language
  newArticle.df[m,6] <- artYear
  newArticle.df[m,7] <- artMonth
  newArticle.df[m,8] <- artDay
  newArticle.df[m,9] <- pubYear
  newArticle.df[m,10] <- pubMonth
}

```

```{r}
#commented out so not seen in a knitted file
newArticle.df
```

```{r}

newAuthor.df <- data.frame(PMID = numeric(),
                          lastName = character(),
                          foreName = character(),
                          initials = character(),
                          affiliation = character(),
                          stringsAsFactors = F)

colnames(newAuthor.df) <- c("PMID","lastName","foreName", 
                             "initials","affiliation")

r <- xmlRoot(xml_data)
rowCount <- 1
for (m in 1:19)
{

  PMID <- xpathSApply(r[[m]][[1]], "./PMID", xmlValue)
  if (length(PMID) == 0)
    PMID <- ""
  
  anAuthorNodeList <- r[[m]][[1]][['Article']][['AuthorList']] 
  
  j<-xmlSize(anAuthorNodeList)
  
  
  for (k in 1:j){
    
    node <-anAuthorNodeList[[k]]
    lastName <- xpathSApply(node, "./LastName", xmlValue)
    foreName <- xpathSApply(node, "./ForeName", xmlValue)
    initials <- xpathSApply(node, "./Initials", xmlValue)
    affiliation <- xpathSApply(node, "./Affiliation", xmlValue)
    
    if (length(lastName) == 0)
      lastName <- ""
    if (length(foreName) == 0)
      foreName <- ""
    if (length(initials) == 0)
      initials <- ""
    if (length(affiliation) == 0)
      affiliation <- ""
    
    newAuthor.df[rowCount,1] <- PMID
    newAuthor.df[rowCount,2] <- lastName
    newAuthor.df[rowCount,3] <- foreName
    newAuthor.df[rowCount,4] <- initials
    newAuthor.df[rowCount,5] <- affiliation
    
    
    rowCount <- rowCount+1
  }

}
  
```
```{r}
#commented out so not seen in a knitted file
#newAuthor.df
```


```{r}

newHistory.df <- data.frame(PMID = numeric(),
                          pubStatus = character(),
                          year = numeric(),
                          month = numeric(),
                          day = numeric(),
                          #hour and minute not useful for analysis?
                          stringsAsFactors = F)

colnames(newHistory.df) <- c("PMID","pubStatus","year", 
                             "month","day")

r <- xmlRoot(xml_data)
rowCount <- 1
for (m in 1:19)
{

  PMID <- xpathSApply(r[[m]][[1]], "./PMID", xmlValue)
  if (length(PMID) == 0)
    PMID <- ""
  
  aHistoryList <- r[[m]][['PubmedData']][['History']]
  
  j<-xmlSize(aHistoryList)
  
  
  for (k in 1:j){
    
    node <-aHistoryList[[k]]
    
    pubStatus <- xmlGetAttr(node,'PubStatus')

    year <- xpathSApply(node, "./Year", xmlValue)
    month <- xpathSApply(node, "./Month", xmlValue)
    day <- xpathSApply(node, "./Day", xmlValue)
    

    if (length(pubStatus) == 0)
      pubStatus <- ""
    if (length(year) == 0)
      year <- ""
    if (length(month) == 0)
      month <- ""
    if (length(day) == 0)
      day <- ""
    
    newHistory.df[rowCount,1] <- PMID
    newHistory.df[rowCount,2] <- pubStatus
    newHistory.df[rowCount,3] <- year
    newHistory.df[rowCount,4] <- month
    newHistory.df[rowCount,5] <- day
    
    
    rowCount <- rowCount+1
  }

}
  
```


```{r}
#commented out so not seen in a knitted file
newHistory.df
```



Clear tables as needed

```{sql connection=dbs}
DROP TABLE IF EXISTS Journal
```

```{sql connection=dbs}
DROP TABLE IF EXISTS Article
```

```{sql connection=dbs}
DROP TABLE IF EXISTS Authorship
```

```{sql connection=dbs}
DROP TABLE IF EXISTS Author
```

```{sql connection=dbs}
DROP TABLE IF EXISTS History

```


Create tables from ERD

```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Journal (
  ISSN varchar(255) primary key,
  title varchar(255),
  ISOabbrevation varchar(255)

  );
```

  
```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Article (
  PMID int(255) NOT NULL,
  journalISSN varchar(255),
  title varchar(255),
  pagination varchar(255),
  language varchar(255),
  FOREIGN KEY (journalISSN ) REFERENCES Journal(ISSN)
  );
```

  histKey INTEGER primary key AUTOINCREMENT,
  
  use compound key instead?
  

```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS History (
  PMID int(255),
  pubStatus varchar(255),
  year int(255),
  month int(255),
  day int(255),
  PRIMARY  KEY (PMID, pubStatus),
  FOREIGN KEY (PMID) REFERENCES Article(PMID)
  );
```

adding in this lookup table
might need compound primary key?
```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Authorship (
  lookupKey INTEGER primary key AUTOINCREMENT,
  PMID int(255),
  lastName varchar(255),
  foreName varchar(255),
  FOREIGN KEY (PMID) REFERENCES Article(PMID),
  FOREIGN KEY (lastName, foreName) REFERENCES Author(lastName, foreName)
  );
```

  PMID int(255),
  
  ,
  FOREIGN KEY (PMID) REFERENCES Article(PMID)
```{sql connection=dbs}
CREATE TABLE IF NOT EXISTS Author (
  authorKey INTEGER primary key AUTOINCREMENT,
  lastName varchar(255),
  foreName varchar(255),
  initials varchar(255),
  affiliation varchar(255)
  );
```



Check all tables have been correctly added to database
```{r}
dbListTables(dbs)

```


Inserting data (dataframe) into tables that have been created in pubMedData database

```{r}
dbWriteTable(dbs, "journalData",newJournal.df , overwrite = TRUE)
```

```{sql connection=dbs}

SELECT DISTINCT 
ISSN,journalTitle,ISOabbrevation from journalData 
```

```{sql connection=dbs}
INSERT INTO Journal(ISSN , title,ISOabbrevation)
SELECT DISTINCT 
ISSN,journalTitle,ISOabbrevation from journalData 


```


```{sql connection=dbs}

SELECT * from journal LIMIT 10;

```

```{sql connection=dbs}

--SELECT COUNT(*) from journal;
SELECT * from journal;
```


Drop temporary table for Journal
```{sql connection=dbs}
DROP TABLE journalData
```

write article df to database
```{r}
dbWriteTable(dbs, "articleData",newArticle.df )
```


```{sql connection=dbs}

SELECT distinct PMID from articleData
```


Remove year/ month/day?
, year,month,day
, artYear,artMonth,artDay
```{sql connection=dbs}
INSERT INTO Article (PMID , journalISSN, title, pagination,language)
SELECT  PMID, journalISSN, articleTitle, pagination,language
FROM articleData


```

```{sql connection=dbs}

SELECT * from Article LIMIT 10
```

```{sql connection=dbs}
DROP TABLE articleData
```



```{r}
dbWriteTable(dbs, "histData",newHistory.df , overwrite = TRUE)
```

History information for the 19 published articles, use year-month-date form this table for star schema
```{sql connection=dbs}

SELECT  DiSTINCT * FROM histData  WHERE pubStatus = "pubmed" 
```

```{sql connection=dbs}
INSERT INTO History (PMID , pubStatus, year, month,day)
SELECT  PMID , pubStatus, year, month,day
FROM histData


```

```{sql connection=dbs}

SELECT * from History LIMIT 10
```


```{r}
dbWriteTable(dbs, "authorData",newAuthor.df, overwrite = TRUE)
```



```{sql connection=dbs}

SELECT* from authorData
```


```{sql connection=dbs}
INSERT INTO Author ( lastName, foreName, initials,affiliation)
SELECT   lastName, foreName, initials,affiliation
FROM authorData

```


```{sql connection=dbs}

SELECT distinct * from Author limit 10
```


Initials is not included in the keys for Authorship because it dosent impact the results. 84 unique first and last name pairs, and 84 first, last and initial pairs.
```{sql connection=dbs}
INSERT INTO Authorship ( PMID, lastName, foreName)
SELECT   PMID, lastName, foreName
FROM authorData
```


```{sql connection=dbs}

SELECT DISTINCT * from Authorship
```


```{sql connection=dbs}
DROP TABLE authorData
```


### Part 2
## Creae new and db Star schema



```{r}
star.dbs <- dbConnect(RSQLite::SQLite(), "pubMedStar0.db")
```



```{sql connection=star.dbs}
--use to clear tables
DROP TABLE IF EXISTS dimAuthor;
```


```{sql connection=star.dbs}
DROP TABLE IF EXISTS dimPubDate;
```

```{sql connection=star.dbs}
DROP TABLE IF EXISTS dimJournal;
```

```{sql connection=star.dbs}
DROP TABLE IF EXISTS dimHistory;
```

```{sql connection=star.dbs}
DROP TABLE IF EXISTS factArticle;

```

tracks number of articles per quarter, month, year
```{sql connection=star.dbs}
DROP TABLE IF EXISTS numArticleSummary;
```

## realize star schema tables
```{sql connection=star.dbs}
CREATE TABLE IF NOT EXISTS dimAuthor(
  authorRef INTEGER NOT NULL, 
 -- PMID INTEGER NOT NULL,
  lastName TEXT NULL, 
  foreName TEXT NULL, 
  initials TEXT NULL,
  affiliation TEXT NULL, 
  PRIMARY KEY(authorRef) 
  );
```

#pubMedDate col
```{sql connection=star.dbs}
CREATE TABLE IF NOT EXISTS dimPubDate(
  dateRef INTEGER PRIMARY KEY AUTOINCREMENT,
  PMID INTEGER NULL,
  datePublished TEXT,
  month INTEGER NULL,
  year INTEGER NULL,
  quarter INTEGER
  );

```

update this to assocate with every article (even if multiple articles published to same journal, dimension table
should be in context of specific article, center table?, or could just grab from article itself)
```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS dimJournal(
  journalRef INTEGER NOT NULL,
  ISSN TEXT NOT NULL,
  title TEXT NULL,
  --volume TEXT NULL,
  --issue TEXT NULL,
  PRIMARY KEY (journalRef)
  );

```


may need to add pubStatus later
```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS dimHistory(
  historyRef INTEGER PRIMARY KEY AUTOINCREMENT,
  articleId INTEGER NULL,
  articleTitle TEXT NULL,
  pubStatus INTEGER NULL
  );

```


compound key - (pmid, authorRef) connect author to specific article
```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS factArticle(
  PMID INTEGER NOT NULL,
  aTitle TEXT,
  authorRef INTEGER NOT NULL, 
  journalRef INTEGER NOT NULL,
  dateRef INTEGER NOT NULL,
  historyRef INTEGER NOT NULL,
  FOREIGN KEY (authorRef) REFERENCES dimAuthor(authorRef),
  FOREIGN KEY (journalRef) REFERENCES dimJournal(journalRef), 
  FOREIGN KEY (dateRef) REFERENCES dimPubDate(dateRef),
  FOREIGN KEY (historyRef) REFERENCES dimHistory(historyRef),
  PRIMARY KEY (PMID, authorRef)
);

```


```{sql connection=star.dbs}

CREATE TABLE IF NOT EXISTS numArticleSummary(
  summaryId INTEGER,
  numOfArticles INTEGER NOT NULL,
  quarter INTEGER,
  year INTEGER, 
  month INTEGER,
  PRIMARY KEY (summaryId)
);

```


```{r}
dbListTables(star.dbs)
dbListTables(dbs)
```


Purpose of star schema is to have eaisly accessible look up tables (LinkedIn learning) - Context tables 
Part 2. Populate Star Schema tables using populated OLTP database. 
First, update the dimension tables. Then we can use look up keys for these to  populate 

Create temp (star schema) data frames from dbs database using queries to populate Star Schema tables

```{r}

#dbs <- dbConnect(RSQLite::SQLite(), "pubMed0.db")
#query database to get author
#dbSendQuery(dbs, "SELECT * FROM Author LIMIT 10")

sqlCmd = "SELECT authorKey FROM Author"
authorRef = dbGetQuery(dbs, sqlCmd)
authorRef 

sqlCmd = "SELECT foreName FROM Author"
foreName = dbGetQuery(dbs, sqlCmd)
foreName

sqlCmd = "SELECT lastName FROM Author"
lastName = dbGetQuery(dbs, sqlCmd)
lastName
 
sqlCmd = "SELECT initials FROM Author"
initials = dbGetQuery(dbs, sqlCmd)
initials

sqlCmd = "SELECT affiliation  FROM Author"
affiliation  = dbGetQuery(dbs, sqlCmd)
affiliation 

df_AuthorStar = data.frame(cbind(authorRef, foreName, lastName, initials, affiliation))
df_AuthorStar

head(df_AuthorStar)

#headers of dataframe once collected cols from dbs
names(df_AuthorStar)
#rename authorKey for star schema table
df_AuthorStar <- df_AuthorStar %>% rename(authorRef = authorKey)
#names(df_AuthorStar)

```

Populate Star schema tables 
```{r}
#star.dbs <- dbConnect(RSQLite::SQLite(), "pubMedStar0.db")

dbWriteTable( star.dbs, "dimAuthor", df_AuthorStar, field.types = NULL, row.names = FALSE, 
              overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimAuthor")

#dbListTables(star.dbs)
```



```{r}
issn = dbGetQuery(dbs, "SELECT ISSN FROM JOURNAL")
#issn

journalTitle = dbGetQuery(dbs, "SELECT TITLE FROM JOURNAL")
#journalTitle

df_Journal = cbind(issn,journalTitle)
head(df_Journal)

dbWriteTable( star.dbs, "dimJournal", df_Journal, field.types = NULL, row.names = FALSE, 
              overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimJournal")

dbListTables(star.dbs)
```


```{sql connection=star.dbs}

SELECT * FROM dimJournal LIMIT 10;

```


create temp table to text parsing pub date
Saves the resulting table query regular database into a datafram in R, which will be used to write to dimHistory
```{sql connection=dbs, output.var="df_dimHistory"}

SELECT History.PMID AS PMID,
  History.pubStatus AS pubStatus,
  History.day || "-" || History.month || "-" || History.year AS datePublished,
  CASE
    WHEN History.month BETWEEN 1 AND 3 THEN 1
    WHEN History.month BETWEEN 4 AND 6 THEN 2
    WHEN History.month BETWEEN 7 AND 9 THEN 3
    WHEN History.month Between 10 AND 12 THEN 4
  END AS quarter
  FROM History

```

Populate article fact table now that dimension/context tables have been populated 
output.var="df_factArticle"


```{r}

sqlCmd = "SELECT title FROM Article "
title = dbGetQuery(dbs, sqlCmd)
title

sqlCmd = "SELECT historyRef FROM dimHistory "
historyRef = dbGetQuery(star.dbs, sqlCmd)
#historyRef

sqlCmd = "SELECT DISTINCT authorRef FROM dimAuthor "
authorRef = dbGetQuery(star.dbs, sqlCmd)
authorRef

sqlCmd = "SELECT historyRef FROM dimHistory "
historyRef = dbGetQuery(star.dbs, sqlCmd)
historyRef

sqlCmd = "SELECT journalRef FROM dimJournal"
journalRef = dbGetQuery(star.dbs, sqlCmd)
journalRef

sqlCmd = "SELECT * FROM dimPubDate"
dateRef = dbGetQuery(star.dbs, sqlCmd)
dateRef

df_factArt = cbind(authorRef,journalRef,dateRef,historyRef)
head(df_factArt)

dbWriteTable( star.dbs, "dimJournal", df_Journal, field.types = NULL, row.names = FALSE, 
              overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimJournal")

dbListTables(star.dbs)

#can query here to get artciles per quarter and other facts etc


```





testing will delete
```{sql connection=dbs}

SELECT
 History.day || "-" || History.month || "-" || History.year AS date1,
  CASE
    WHEN History.month BETWEEN 1 AND 3 THEN 1
    WHEN History.month BETWEEN 4 AND 6 THEN 2
    WHEN History.month BETWEEN 7 AND 9 THEN 3
    WHEN History.month Between 10 AND 12 THEN 4
  END
  FROM History

```



Query database to populate dimPubDate table (date dimension table)
## Output dimensoon table: dimHistory articleId, articleTitle, pubStatus
```{r}

sqlCmd = "SELECT day FROM History"
Day0 = dbGetQuery(dbs, sqlCmd)
#Day0

sqlCmd = "SELECT month FROM History"
Month0 = dbGetQuery(dbs, sqlCmd)
#Month0

sqlCmd = "SELECT year FROM History"
Year0 = dbGetQuery(dbs, sqlCmd)

sqlCmd = "SELECT pubStatus FROM History"
pubstatus = dbGetQuery(dbs, sqlCmd)

#create date string from day month yr columns queried
dfTest<-cbind(Day0,Month0,Year0, stringsAsFactors = FALSE)
#dfTest

#append full date column to dfTest, redult df of article stages by dates, mo, yr, day 
dfTest$date <- paste(dfTest$day,dfTest$month,dfTest$year, sep = '-')
date1 <- data.frame(dfTest$date)

PMID <- df_dimHistory$PMID
#PMID
quarter <- df_dimHistory$quarter
#quarter

#probably not the best way to bind but every pub stage of an article (pubstatus) to align with title
#in order to add to history, i think it can be queries for useful history timeline of each article
sqlCmd = "SELECT History.pubStatus, Article.title
FROM History
JOIN Article ON History.PMID = Article.PMID;"
pubAndTitle = dbGetQuery(dbs, sqlCmd)
pubAndTitle

sqlCmd = "SELECT title FROM Article"
articleTitle = dbGetQuery(dbs, sqlCmd)

#create dataframe for dimHistory dimension table
df_dHistory <- data.frame(cbind(PMID,pubAndTitle))
df_dHistory<- df_dHistory %>% rename(articleId = PMID)
df_dHistory<- df_dHistory %>% rename(articleTitle = title)
df_dHistory

#create dataframe for pubDate dimension table
df_pubDateStar2 <- data.frame(cbind(PMID,date1,Month0,Year0,quarter))
df_pubDateStar2 <- df_pubDateStar2 %>% rename(datePublished = dfTest.date)
#checking headers
#names(df_pubDateStar)
df_pubDateStar2

# insert pubdate df to pubDate dimension table of star schema
dbWriteTable( star.dbs, "dimPubDate", df_pubDateStar2, field.types = NULL, row.names = FALSE,
               overwrite = FALSE, append = TRUE, allow.keywords = FALSE )


dbReadTable( star.dbs, "dimPubDate")
```

## Dimensoon table: dimPubDate
Populate the dimension pubDate table of star schema and read the table to confirm its populated
Fields: historyRef, articleId (pmid), articleTitle, pubStatus
```{r}
# insert History df to history dimension table of star schema
dbWriteTable( star.dbs, "dimHistory", df_dHistory, field.types = NULL, row.names = FALSE,
               overwrite = FALSE, append = TRUE, allow.keywords = FALSE )

dbReadTable( star.dbs, "dimHistory")

```



In the same schema as the previous step, create and populate a summary fact table that represents number of articles per time period (quarter, year) by author and by journal. Include the image of an updated ERD that contains the fact table. Populate the fact table in R. When building the schema, look a head to Part 3 as the schema is dependent on the eventual OLAP queries.

Query that sorts by quarter - get from star schema
```{r}

#subquery that groups by articles, resulting in 19 unique articles and their history
to = " SELECT pmid, quarter FROM dimHistory
GROUP BY PMID "

sqlCmd = " SELECT quarter, COUNT(*) AS 'numOfarticles' FROM (SELECT pmid, quarter FROM dimHistory
GROUP BY PMID) GROUP BY quarter
"

#get mpid and quarter of each unique article
# (SELECT PMID, quarter FROM (SELECT * FROM dimHistory GROUP BY PMID)

dbGetQuery(star.dbs, sqlCmd)

```




```{r}
dbGetQuery(dbs, 'SELECT * FROM History')
```






```{r}

dbDisconnect(dbs)
dbDisconnect(star.dbs)

```


### Part 3 use the OLAP star/snowflake schema to do some (simple) data mining




Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

